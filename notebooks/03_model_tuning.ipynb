{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51499c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).mean())\n",
    "\n",
    "def train_linear_regression_reg(X, y, r=0.001):\n",
    "    ones = np.ones(X.shape[0])\n",
    "    X = np.column_stack([ones, X])\n",
    "    XTX = X.T.dot(X)\n",
    "    XTX = XTX + r * np.eye(XTX.shape[0])\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    w = XTX_inv.dot(X.T).dot(y)\n",
    "    return w[0], w[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ef93b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X(df):\n",
    "    df = df.copy()\n",
    "    base = ['engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg', 'popularity']\n",
    "    features = base.copy()\n",
    "    \n",
    "    # –í–æ–∑—Ä–∞—Å—Ç\n",
    "    df['age'] = 2017 - df['year']\n",
    "    features.append('age')\n",
    "    \n",
    "    # –î–≤–µ—Ä–∏\n",
    "    for v in [2, 3, 4]:\n",
    "        feature = f'num_doors_{v}'\n",
    "        df[feature] = (df['number_of_doors'] == v).astype(int)\n",
    "        features.append(feature)\n",
    "    \n",
    "    # –¢–æ–ø-5 –º–∞—Ä–æ–∫\n",
    "    top_makes = ['ford', 'chevrolet', 'toyota', 'nissan', 'honda']\n",
    "    for make in top_makes:\n",
    "        feature = f'is_make_{make}'\n",
    "        df[feature] = (df['make'] == make).astype(int)\n",
    "        features.append(feature)\n",
    "    \n",
    "    # –¢–∏–ø —Ç–æ–ø–ª–∏–≤–∞\n",
    "    fuel_types = [\n",
    "        'regular unleaded',\n",
    "        'premium unleaded (required)',\n",
    "        'premium unleaded (recommended)',\n",
    "        'flex-fuel (unleaded/e85)',\n",
    "        'diesel'\n",
    "    ]\n",
    "    for fuel in fuel_types:\n",
    "        clean_name = fuel.replace(' ', '_').replace('(', '').replace(')', '').replace('/', '_')\n",
    "        feature = f'is_fuel_{clean_name}'\n",
    "        df[feature] = (df['engine_fuel_type'] == fuel).astype(int)\n",
    "        features.append(feature)\n",
    "    \n",
    "    # –¢—Ä–∞–Ω—Å–º–∏—Å—Å–∏—è\n",
    "    transmissions = ['automatic', 'manual', 'automated_manual']\n",
    "    for trans in transmissions:\n",
    "        feature = f'is_trans_{trans}'\n",
    "        df[feature] = (df['transmission_type'] == trans).astype(int)\n",
    "        features.append(feature)\n",
    "    \n",
    "    # –ü—Ä–∏–≤–æ–¥\n",
    "    drives = ['front wheel drive', 'rear wheel drive', 'all wheel drive', 'four wheel drive']\n",
    "    for drive in drives:\n",
    "        clean_drive = drive.replace(' ', '_')\n",
    "        feature = f'is_drive_{clean_drive}'\n",
    "        df[feature] = (df['driven_wheels'] == drive).astype(int)\n",
    "        features.append(feature)\n",
    "    \n",
    "    # –†–∞–∑–º–µ—Ä\n",
    "    sizes = ['compact', 'midsize', 'large']\n",
    "    for size in sizes:\n",
    "        feature = f'is_size_{size}'\n",
    "        df[feature] = (df['vehicle_size'] == size).astype(int)\n",
    "        features.append(feature)\n",
    "    \n",
    "    # –°—Ç–∏–ª—å –∫—É–∑–æ–≤–∞\n",
    "    styles = ['sedan', '4dr_suv', 'crew_cab_pickup', 'coupe', '4dr_hatchback']\n",
    "    for style in styles:\n",
    "        feature = f'is_style_{style}'\n",
    "        df[feature] = (df['vehicle_style'] == style).astype(int)\n",
    "        features.append(feature)\n",
    "    \n",
    "    # –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    df_num = df[features].fillna(0)\n",
    "    X = df_num.values\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c5caabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 7007, Val: 2336, Test: 2336\n"
     ]
    }
   ],
   "source": [
    "# --- –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–ø–æ–ª–Ω–∞—è) ---\n",
    "with open('../data/data.csv', 'r', encoding='utf-8') as f:\n",
    "    raw = f.read().strip()\n",
    "\n",
    "fixed = re.sub(r'(\\d)([A-Z])', r'\\1\\n\\2', raw)\n",
    "with open('../data/data_fixed.csv', 'w', encoding='utf-8') as f:\n",
    "    f.write(fixed)\n",
    "\n",
    "columns = [\n",
    "    'make', 'model', 'year', 'engine_fuel_type', 'engine_hp', 'engine_cylinders',\n",
    "    'transmission_type', 'driven_wheels', 'number_of_doors', 'market_category',\n",
    "    'vehicle_size', 'vehicle_style', 'highway_mpg', 'city_mpg', 'popularity', 'msrp'\n",
    "]\n",
    "df = pd.read_csv('../data/data_fixed.csv', header=None, names=columns)\n",
    "\n",
    "# –ß–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "numeric_cols = ['year', 'engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg', 'popularity', 'msrp', 'number_of_doors']\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# –°—Ç—Ä–æ–∫–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "str_cols = df.select_dtypes(include='object').columns\n",
    "for col in str_cols:\n",
    "    df[col] = df[col].astype(str).str.lower().str.replace(' ', '_')\n",
    "\n",
    "# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ü–µ–Ω–æ–π\n",
    "df = df.dropna(subset=['msrp'])\n",
    "df['log_msrp'] = np.log1p(df['msrp'])\n",
    "\n",
    "# –†–∞–∑–±–∏–µ–Ω–∏–µ\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=2)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=2)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train['log_msrp'].values\n",
    "y_val = df_val['log_msrp'].values\n",
    "y_test = df_test['log_msrp'].values\n",
    "\n",
    "print(f\"Train: {len(df_train)}, Val: {len(df_val)}, Test: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9678c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r =    1e-05 ‚Üí RMSE = 0.49923\n",
      "r =   0.0001 ‚Üí RMSE = 0.49923\n",
      "r =    0.001 ‚Üí RMSE = 0.49924\n",
      "r =     0.01 ‚Üí RMSE = 0.49934\n",
      "r =      0.1 ‚Üí RMSE = 0.50036\n",
      "r =        1 ‚Üí RMSE = 0.50687\n",
      "r =       10 ‚Üí RMSE = 0.52221\n",
      "\n",
      "‚úÖ –õ—É—á—à–∏–π r = 1e-05, RMSE = 0.49923\n"
     ]
    }
   ],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "X_train = prepare_X(df_train)\n",
    "X_val = prepare_X(df_val)\n",
    "\n",
    "# –î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏\n",
    "r_values = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "scores = []\n",
    "\n",
    "for r in r_values:\n",
    "    w0, w = train_linear_regression_reg(X_train, y_train, r=r)\n",
    "    y_pred = w0 + X_val.dot(w)\n",
    "    score = rmse(y_val, y_pred)\n",
    "    scores.append(score)\n",
    "    print(f'r = {r:>8} ‚Üí RMSE = {score:.5f}')\n",
    "\n",
    "# –í—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ r\n",
    "best_r = r_values[np.argmin(scores)]\n",
    "best_rmse = min(scores)\n",
    "print(f'\\n‚úÖ –õ—É—á—à–∏–π r = {best_r}, RMSE = {best_rmse:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84382001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X_with_interactions(df):\n",
    "    df = df.copy()\n",
    "    base = ['engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg', 'popularity']\n",
    "    features = base.copy()\n",
    "    \n",
    "    # –í–æ–∑—Ä–∞—Å—Ç –∞–≤—Ç–æ–º–æ–±–∏–ª—è\n",
    "    df['age'] = 2017 - df['year']\n",
    "    features.append('age')\n",
    "    \n",
    "    # –ë–∞–∑–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    top_makes = ['ford', 'chevrolet', 'toyota', 'nissan', 'honda']\n",
    "    for make in top_makes:\n",
    "        feature = f'is_make_{make}'\n",
    "        df[feature] = (df['make'] == make).astype(int)\n",
    "        features.append(feature)\n",
    "    \n",
    "    # –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è: –º–æ—â–Ω–æ—Å—Ç—å √ó –º–∞—Ä–∫–∞\n",
    "    for make in top_makes:\n",
    "        feat_name = f'hp_x_{make}'\n",
    "        df[feat_name] = df['engine_hp'] * (df['make'] == make).astype(int)\n",
    "        features.append(feat_name)\n",
    "    \n",
    "    # –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è: –≤–æ–∑—Ä–∞—Å—Ç √ó –º–∞—Ä–∫–∞\n",
    "    for make in top_makes:\n",
    "        feat_name = f'age_x_{make}'\n",
    "        df[feat_name] = df['age'] * (df['make'] == make).astype(int)\n",
    "        features.append(feat_name)\n",
    "    \n",
    "    # –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ: —Ç–∏–ø —Ç–æ–ø–ª–∏–≤–∞ √ó —Ü–∏–ª–∏–Ω–¥—Ä—ã\n",
    "    df['fuel_premium_x_cyl'] = df['engine_cylinders'] * (df['engine_fuel_type'] == 'premium unleaded (required)').astype(int)\n",
    "    features.append('fuel_premium_x_cyl')\n",
    "    \n",
    "    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–¥–≤–µ—Ä–∏, —Ç—Ä–∞–Ω—Å–º–∏—Å—Å–∏—è –∏ —Ç.–¥.) ‚Äî –¥–æ–±–∞–≤–∏–º –ø–æ–∑–∂–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "    # –ù–∞ –¥–∞–Ω–Ω–æ–º —ç—Ç–∞–ø–µ –æ–≥—Ä–∞–Ω–∏—á–∏–º—Å—è –∫–ª—é—á–µ–≤—ã–º–∏\n",
    "    \n",
    "    df_num = df[features].fillna(0)\n",
    "    X = df_num.values\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "050d9818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE —Å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è–º–∏: 0.50205\n"
     ]
    }
   ],
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ —Å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è–º–∏\n",
    "X_train_int = prepare_X_with_interactions(df_train)\n",
    "X_val_int = prepare_X_with_interactions(df_val)\n",
    "\n",
    "w0, w = train_linear_regression_reg(X_train_int, y_train, r=1e-05)\n",
    "y_pred_int = w0 + X_val_int.dot(w)\n",
    "rmse_int = rmse(y_val, y_pred_int)\n",
    "\n",
    "print(f\"RMSE —Å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è–º–∏: {rmse_int:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7315149",
   "metadata": {},
   "source": [
    "–Ω–∞—á–∞–ª–æ –ª–æ–≥.—Ä–µ–≥—Ä–µ—Å—Å–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31331b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü–æ—Ä–æ–≥–∏: –¥–µ—à—ë–≤—ã–π ‚â§ $24,017, —Å—Ä–µ–¥–Ω–∏–π ‚â§ $36,625\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ (train):\n",
      "0    2296\n",
      "1    2323\n",
      "2    2388\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª–∏–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã —Ü–µ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–≤–∞–Ω—Ç–∏–ª–µ–π\n",
    "price_quantiles = df['msrp'].quantile([0.33, 0.66]).values\n",
    "low_threshold, high_threshold = price_quantiles\n",
    "\n",
    "def price_class(price):\n",
    "    if price <= low_threshold:\n",
    "        return 0  # \"–¥–µ—à—ë–≤—ã–π\"\n",
    "    elif price <= high_threshold:\n",
    "        return 1  # \"—Å—Ä–µ–¥–Ω–∏–π\"\n",
    "    else:\n",
    "        return 2  # \"–¥–æ—Ä–æ–≥–æ–π\"\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º –∫ –≤—ã–±–æ—Ä–∫–∞–º\n",
    "df_train['price_class'] = df_train['msrp'].apply(price_class)\n",
    "df_val['price_class'] = df_val['msrp'].apply(price_class)\n",
    "df_test['price_class'] = df_test['msrp'].apply(price_class)\n",
    "\n",
    "y_train_clf = df_train['price_class'].values\n",
    "y_val_clf = df_val['price_class'].values\n",
    "\n",
    "print(f\"–ü–æ—Ä–æ–≥–∏: –¥–µ—à—ë–≤—ã–π ‚â§ ${low_threshold:,.0f}, —Å—Ä–µ–¥–Ω–∏–π ‚â§ ${high_threshold:,.0f}\")\n",
    "print(\"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ (train):\")\n",
    "print(pd.Series(y_train_clf).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ab58b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: 0.7551\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     –î–µ—à—ë–≤—ã–π       0.85      0.84      0.84       788\n",
      "     –°—Ä–µ–¥–Ω–∏–π       0.64      0.61      0.62       757\n",
      "     –î–æ—Ä–æ–≥–æ–π       0.77      0.81      0.79       791\n",
      "\n",
      "    accuracy                           0.76      2336\n",
      "   macro avg       0.75      0.75      0.75      2336\n",
      "weighted avg       0.75      0.76      0.75      2336\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\churilinkb\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ —Ñ—É–Ω–∫—Ü–∏—é, —á—Ç–æ –∏ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏)\n",
    "X_train_clf = prepare_X(df_train)\n",
    "X_val_clf = prepare_X(df_val)\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "clf = LogisticRegression(max_iter=1000, random_state=2)\n",
    "clf.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "y_pred_clf = clf.predict(X_val_clf)\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "acc = accuracy_score(y_val_clf, y_pred_clf)\n",
    "print(f\"Accuracy –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {acc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val_clf, y_pred_clf, target_names=['–î–µ—à—ë–≤—ã–π', '–°—Ä–µ–¥–Ω–∏–π', '–î–æ—Ä–æ–≥–æ–π']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25c00dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (–≤–∞—à–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è): 0.49923\n",
      "RMSE (sklearn Ridge):    0.49923\n",
      "–†–∞–∑–Ω–∏—Ü–∞:                 0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "X_train = prepare_X(df_train)\n",
    "X_val = prepare_X(df_val)\n",
    "\n",
    "# –í–∞—à–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "w0, w = train_linear_regression_reg(X_train, y_train, r=1e-05)\n",
    "y_pred_custom = w0 + X_val.dot(w)\n",
    "rmse_custom = rmse(y_val, y_pred_custom)\n",
    "\n",
    "# Sklearn Ridge\n",
    "ridge = Ridge(alpha=1e-05, solver='cholesky')\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_sklearn = ridge.predict(X_val)\n",
    "rmse_sklearn = rmse(y_val, y_pred_sklearn)\n",
    "\n",
    "print(f\"RMSE (–≤–∞—à–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è): {rmse_custom:.5f}\")\n",
    "print(f\"RMSE (sklearn Ridge):    {rmse_sklearn:.5f}\")\n",
    "print(f\"–†–∞–∑–Ω–∏—Ü–∞:                 {abs(rmse_custom - rmse_sklearn):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0394c657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ '../models/model_weights.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –Ω–∞ –ø–æ–ª–Ω—ã—Ö —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "X_train_full = prepare_X(df_train)\n",
    "w0_final, w_final = train_linear_regression_reg(X_train_full, y_train, r=1e-05)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏\n",
    "model_weights = {'w0': w0_final, 'w': w_final}\n",
    "with open('../models/model_weights.pkl', 'wb') as f:\n",
    "    pickle.dump(model_weights, f)\n",
    "\n",
    "print(\"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ '../models/model_weights.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "057e0a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(car_dict, model_path='../models/model_weights.pkl'):\n",
    "    \"\"\"\n",
    "    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ü–µ–Ω—É –∞–≤—Ç–æ–º–æ–±–∏–ª—è –ø–æ –µ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º.\n",
    "    \n",
    "    car_dict: —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "    –ü—Ä–∏–º–µ—Ä:\n",
    "        {\n",
    "            'make': 'toyota',\n",
    "            'model': 'rav4',\n",
    "            'year': 2017,\n",
    "            'engine_fuel_type': 'regular unleaded',\n",
    "            'engine_hp': 176,\n",
    "            'engine_cylinders': 4,\n",
    "            'transmission_type': 'automatic',\n",
    "            'driven_wheels': 'all wheel drive',\n",
    "            'number_of_doors': 4,\n",
    "            'market_category': 'crossover',\n",
    "            'vehicle_size': 'midsize',\n",
    "            'vehicle_style': '4dr suv',\n",
    "            'highway_mpg': 28,\n",
    "            'city_mpg': 22,\n",
    "            'popularity': 2031\n",
    "        }\n",
    "    \"\"\"\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "    with open(model_path, 'rb') as f:\n",
    "        weights = pickle.load(f)\n",
    "    w0, w = weights['w0'], weights['w']\n",
    "    \n",
    "    # –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –∏–∑ —Å–ª–æ–≤–∞—Ä—è\n",
    "    df_input = pd.DataFrame([car_dict])\n",
    "    \n",
    "    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    X_input = prepare_X(df_input)\n",
    "    \n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≤ –ª–æ–≥-–º–∞—Å—à—Ç–∞–±–µ\n",
    "    log_price_pred = w0 + X_input.dot(w)\n",
    "    \n",
    "    # –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –¥–æ–ª–ª–∞—Ä—ã\n",
    "    price_pred = np.expm1(log_price_pred[0])\n",
    "    \n",
    "    return price_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6053d67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞: $26,745\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä –∞–≤—Ç–æ–º–æ–±–∏–ª—è\n",
    "new_car = {\n",
    "    'make': 'toyota',\n",
    "    'model': 'rav4',\n",
    "    'year': 2017,\n",
    "    'engine_fuel_type': 'regular unleaded',\n",
    "    'engine_hp': 176,\n",
    "    'engine_cylinders': 4,\n",
    "    'transmission_type': 'automatic',\n",
    "    'driven_wheels': 'all wheel drive',\n",
    "    'number_of_doors': 4,\n",
    "    'market_category': 'crossover',\n",
    "    'vehicle_size': 'midsize',\n",
    "    'vehicle_style': '4dr suv',\n",
    "    'highway_mpg': 28,\n",
    "    'city_mpg': 22,\n",
    "    'popularity': 2031\n",
    "}\n",
    "\n",
    "predicted_price = predict_price(new_car)\n",
    "print(f\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞: ${predicted_price:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95141f06",
   "metadata": {},
   "source": [
    "üìå –ò—Ç–æ–≥–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤—Å–µ–≥–æ –ø–ª–∞–Ω–∞:\n",
    "‚úÖ –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ r ‚Üí r = 1e-05\n",
    "‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ‚Üí –Ω–µ —É–ª—É—á—à–∏–ª–æ RMSE, —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–Ω—è—Ç–æ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ\n",
    "‚úÖ –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ —Ü–µ–Ω ‚Üí Accuracy = 75.5%, —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã\n",
    "‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å sklearn.linear_model.Ridge ‚Üí RMSE –∏–¥–µ–Ω—Ç–∏—á–µ–Ω, —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞\n",
    "‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ‚Üí —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
